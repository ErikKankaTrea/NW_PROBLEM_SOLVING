{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\New_Work\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common_paths import get_data_path, get_output_path\n",
    "from src.common_paths import get_data_path, get_output_path\n",
    "from src.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_space = re.compile(u\"[/\\|\\n(\\; )|(\\: )|( \\()|(\\) )|( \\\")|(\\\" )|( \\')|(\\' )]\")\n",
    "symbols_to_remove = re.compile(u\"[\\\"\\'\\$\\€\\£\\(\\)\\:\\[\\]\\.\\,\\-]\")\n",
    "space_repetition = re.compile(u\" {2,}\")\n",
    "key_words_to_remove = re.compile(u\"gmbh\")\n",
    "\n",
    "def canonize_language(df, text_var):\n",
    "    text_var_clean= text_var+'_clean'\n",
    "    cleaned_var=df[text_var].apply(lambda x: re.sub(symbols_to_remove, \"\", x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: x.lower())\n",
    "    cleaned_var=cleaned_var.apply(lambda x: re.sub(key_words_to_remove, \"\", x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: unicodedata.normalize('NFKD', x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: re.sub(space_repetition, \"\", x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: str.strip(x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: re.sub(u\"\\s\", \"_\", x))\n",
    "    return cleaned_var\n",
    "\n",
    "\n",
    "def match_checker(df1, df2, key, aux_how):\n",
    "    df2[\"aux\"] = 1\n",
    "    aux_df = pd.merge(df1, df2, on = key, how = aux_how)\n",
    "    aux_df[\"aux\"] = aux_df.aux.fillna(0)\n",
    "    num_ids_match= np.sum(aux_df.aux)\n",
    "    print(\"{} var has {} unique values\".format(key, len(np.unique(df1[key]))))\n",
    "    print(\"{} var has {} unique values\".format(key, len(np.unique(df2[key]))))\n",
    "    print(\"Matches {} id rows of entities in profiles\".format(num_ids_match))\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def direct_matcher(df1, df2, key, aux_how):\n",
    "    aux_df = pd.merge(df1, df2, on = key, how = aux_how)\n",
    "    aux_df=aux_df[[\"id_x\", \"id_y\"]]\n",
    "    aux_df.rename(columns={\"id_y\": \"id_profiles\", \"id_x\": \"id_entities\"}, inplace=True)\n",
    "    return(aux_df[[\"id_profiles\", \"id_entities\"]])\n",
    "\n",
    "\n",
    "def eval_fun(profile_ids, aux_vars_ids, matched_df):\n",
    "    # The evaluation will count if all of the profiles have at least 1 entity\n",
    "    # Global and local mean of % matching entitites with profile.\n",
    "    gt_df = pd.read_csv(os.path.join(get_data_path(), \"ground_truth.tsv\"), \n",
    "                                names=aux_vars_ids,\n",
    "                                encoding=\"utf-8\", \n",
    "                                sep=\"\\t\") # .fillna({\"text\": \"empty\"})\n",
    "\n",
    "\n",
    "    # First check: ¿At least all the profiles have one entity?\n",
    "    at_least_all=len(np.unique(gt_df[aux_vars_ids[0]])) == len(np.unique(matched_df[aux_vars_ids[0]]))\n",
    "    if at_least_all:\n",
    "        print(\"1. All profiles have at least one entity\")\n",
    "    else:\n",
    "        print(\"1. Not all profiles have one entity\")\n",
    "    # Second is to measure the percentages:\n",
    "    res_df = pd.DataFrame() # DF with a tuple [a, b, c] where a= # of entitites assigned, b= # of real assigned, c= #matches \n",
    "    for i_id in profile_ids:\n",
    "        entities_assigned=matched_df.loc[matched_df[\"id_profiles\"]==i_id].id_entities.values\n",
    "        entities_assigned = entities_assigned[~np.isnan(entities_assigned)]\n",
    "        num_assigned= len(entities_assigned)\n",
    "        real_entities_assigned=gt_df.loc[gt_df[\"id_profiles\"]==i_id].id_entities.values\n",
    "        real_entities_assigned = real_entities_assigned[~np.isnan(real_entities_assigned)]\n",
    "        real_num_assigned=len(real_entities_assigned)\n",
    "        num_matches=len(set(entities_assigned) & set(real_entities_assigned))\n",
    "        per_match= round(num_matches/real_num_assigned, 2)*100\n",
    "        aux_tuple=[i_id, num_assigned, real_num_assigned, per_match]\n",
    "        aux_df=pd.DataFrame([aux_tuple], columns=[\"id_profile\", \"num_entities_matched\", \"real_entitites_matched\", \"per_match\"])\n",
    "        res_df=res_df.append(aux_df) \n",
    "    return(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = pd.read_csv(os.path.join(get_output_path(), \"enti_data.csv\"), \n",
    "                            encoding=\"utf-8\", \n",
    "                            sep=\";\") # .fillna({\"text\": \"empty\"})\n",
    "\n",
    "profiles_df = pd.read_csv(os.path.join(get_output_path(), \"prof_data.csv\"), \n",
    "                            encoding=\"utf-8\", \n",
    "                            sep=\";\") # .fillna({\"text\": \"empty\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarized ID company_name \n",
    "entities_df['company_name_clean']=canonize_language(df=entities_df, text_var=\"company_name\")\n",
    "profiles_df['company_name_clean']=canonize_language(df=profiles_df, text_var=\"company_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'company_name', 'city', 'country', 'foundation_year_cat',\n",
      "       'company_name_clean'],\n",
      "      dtype='object')\n",
      "Index(['id', 'company_name', 'city', 'country', 'foundation_year_cat',\n",
      "       'company_name_clean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(profiles_df.columns)\n",
    "print(entities_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "\n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "\n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "\n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_merge(profiles_df, entities_df, 'company_name', 'company_name', threshold=80) # TOO MUCH TIME CONSUMING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
