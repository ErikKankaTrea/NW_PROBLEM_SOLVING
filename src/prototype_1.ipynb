{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\New_Work\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common_paths import get_data_path, get_output_path\n",
    "from src.common_paths import get_data_path, get_output_path\n",
    "from src.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_space = re.compile(u\"[/\\|\\n(\\; )|(\\: )|( \\()|(\\) )|( \\\")|(\\\" )|( \\')|(\\' )]\")\n",
    "symbols_to_remove = re.compile(u\"[\\\"\\'\\$\\€\\£\\(\\)\\:\\[\\]\\.\\,\\-]\")\n",
    "space_repetition = re.compile(u\" {2,}\")\n",
    "key_words_to_remove = re.compile(u\"gmbh\")\n",
    "\n",
    "def canonize_language(df, text_var):\n",
    "    text_var_clean= text_var+'_clean'\n",
    "    cleaned_var=df[text_var].apply(lambda x: re.sub(symbols_to_remove, \"\", x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: x.lower())\n",
    "    cleaned_var=cleaned_var.apply(lambda x: re.sub(key_words_to_remove, \"\", x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: unicodedata.normalize('NFKD', x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: re.sub(space_repetition, \"\", x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: str.strip(x))\n",
    "    cleaned_var=cleaned_var.apply(lambda x: re.sub(u\"\\s\", \"_\", x))\n",
    "    return cleaned_var\n",
    "\n",
    "\n",
    "def match_checker(df1, df2, key, aux_how):\n",
    "    df2[\"aux\"] = 1\n",
    "    aux_df = pd.merge(df1, df2, on = key, how = aux_how)\n",
    "    aux_df[\"aux\"] = aux_df.aux.fillna(0)\n",
    "    num_ids_match= np.sum(aux_df.aux)\n",
    "    print(\"{} var has {} unique values\".format(key, len(np.unique(df1[key]))))\n",
    "    print(\"{} var has {} unique values\".format(key, len(np.unique(df2[key]))))\n",
    "    print(\"Matches {} id rows of entities in profiles\".format(num_ids_match))\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def direct_matcher(df1, df2, key, aux_how):\n",
    "    aux_df = pd.merge(df1, df2, on = key, how = aux_how)\n",
    "    aux_df=aux_df[[\"id_x\", \"id_y\"]]\n",
    "    aux_df.rename(columns={\"id_y\": \"id_profiles\", \"id_x\": \"id_entities\"}, inplace=True)\n",
    "    return(aux_df[[\"id_profiles\", \"id_entities\"]])\n",
    "\n",
    "\n",
    "def eval_fun(profile_ids, aux_vars_ids, matched_df):\n",
    "    # The evaluation will count if all of the profiles have at least 1 entity\n",
    "    # Global and local mean of % matching entitites with profile.\n",
    "    gt_df = pd.read_csv(os.path.join(get_data_path(), \"ground_truth.tsv\"), \n",
    "                                names=aux_vars_ids,\n",
    "                                encoding=\"utf-8\", \n",
    "                                sep=\"\\t\") # .fillna({\"text\": \"empty\"})\n",
    "\n",
    "\n",
    "    # First check: ¿At least all the profiles have one entity?\n",
    "    at_least_all=len(np.unique(gt_df[aux_vars_ids[0]])) == len(np.unique(matched_df[aux_vars_ids[0]]))\n",
    "    if at_least_all:\n",
    "        print(\"1. All profiles have at least one entity\")\n",
    "    else:\n",
    "        print(\"1. Not all profiles have one entity\")\n",
    "    # Second is to measure the percentages:\n",
    "    res_df = pd.DataFrame() # DF with a tuple [a, b, c] where a= # of entitites assigned, b= # of real assigned, c= #matches \n",
    "    for i_id in profile_ids:\n",
    "        entities_assigned=matched_df.loc[matched_df[\"id_profiles\"]==i_id].id_entities.values\n",
    "        entities_assigned = entities_assigned[~np.isnan(entities_assigned)]\n",
    "        num_assigned= len(entities_assigned)\n",
    "        real_entities_assigned=gt_df.loc[gt_df[\"id_profiles\"]==i_id].id_entities.values\n",
    "        real_entities_assigned = real_entities_assigned[~np.isnan(real_entities_assigned)]\n",
    "        real_num_assigned=len(real_entities_assigned)\n",
    "        num_matches=len(set(entities_assigned) & set(real_entities_assigned))\n",
    "        per_match= round(num_matches/real_num_assigned, 2)*100\n",
    "        aux_tuple=[i_id, num_assigned, real_num_assigned, per_match]\n",
    "        aux_df=pd.DataFrame([aux_tuple], columns=[\"id_profile\", \"num_entities_matched\", \"real_entitites_matched\", \"per_match\"])\n",
    "        res_df=res_df.append(aux_df) \n",
    "    return(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = pd.read_csv(os.path.join(get_output_path(), \"enti_data.csv\"), \n",
    "                            encoding=\"utf-8\", \n",
    "                            sep=\";\") # .fillna({\"text\": \"empty\"})\n",
    "\n",
    "profiles_df = pd.read_csv(os.path.join(get_output_path(), \"prof_data.csv\"), \n",
    "                            encoding=\"utf-8\", \n",
    "                            sep=\";\") # .fillna({\"text\": \"empty\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarized ID company_name \n",
    "entities_df['company_name_clean']=canonize_language(df=entities_df, text_var=\"company_name\")\n",
    "profiles_df['company_name_clean']=canonize_language(df=profiles_df, text_var=\"company_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Before --------\n",
      "company_name var has 48311 unique values\n",
      "company_name var has 10000 unique values\n",
      "Matches 11013 id rows of entities in profiles\n",
      "-------- Now --------\n",
      "company_name_clean var has 48163 unique values\n",
      "company_name_clean var has 9984 unique values\n",
      "Matches 11296 id rows of entities in profiles\n"
     ]
    }
   ],
   "source": [
    "# How improves the join based on the cleaning variable:\n",
    "print(\"-------- Before --------\")\n",
    "match_checker(df1=entities_df, df2=profiles_df, key=\"company_name\", aux_how=\"right\")\n",
    "print(\"-------- Now --------\")\n",
    "match_checker(df1=entities_df, df2=profiles_df, key=\"company_name_clean\", aux_how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is only an improvement of 3% and its completely unsignificant.\n",
    "round(((11296-11013)/11013), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiles=10000\n",
      "Entities=11265\n",
      "Dimension=(11296, 2)\n"
     ]
    }
   ],
   "source": [
    "# Do the mathing and measure performance:\n",
    "matched_df=direct_matcher(df1=entities_df, df2=profiles_df, key=\"company_name_clean\", aux_how=\"right\")\n",
    "print(\"Profiles={}\".format(len(np.unique(matched_df[\"id_profiles\"]))))\n",
    "print(\"Entities={}\".format(len(np.unique(matched_df[\"id_entities\"]))))\n",
    "print(\"Dimension={}\".format(matched_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. All profiles have at least one entity\n"
     ]
    }
   ],
   "source": [
    "profile_ids=np.unique(profiles_df.id)\n",
    "aux_vars_ids = [\"id_profiles\", \"id_entities\"] #First has to be the profiles id and the second the entitites id name\n",
    "result_proto1_df=eval_fun(profile_ids, aux_vars_ids, matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Recall--\n",
      "Mean average of entity match 60.1314 \n",
      "Median average of entity match 100.0 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_profile</th>\n",
       "      <th>num_entities_matched</th>\n",
       "      <th>real_entitites_matched</th>\n",
       "      <th>per_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.252352e+05</td>\n",
       "      <td>0.756400</td>\n",
       "      <td>1.479900</td>\n",
       "      <td>60.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.847650e+05</td>\n",
       "      <td>1.243066</td>\n",
       "      <td>2.682781</td>\n",
       "      <td>47.897753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.030000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.623500e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.910560e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.048560e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.868021e+06</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_profile  num_entities_matched  real_entitites_matched  \\\n",
       "count  1.000000e+04          10000.000000            10000.000000   \n",
       "mean   4.252352e+05              0.756400                1.479900   \n",
       "std    4.847650e+05              1.243066                2.682781   \n",
       "min    4.030000e+02              0.000000                1.000000   \n",
       "25%    6.623500e+04              0.000000                1.000000   \n",
       "50%    1.910560e+05              1.000000                1.000000   \n",
       "75%    8.048560e+05              1.000000                1.000000   \n",
       "max    1.868021e+06             45.000000               89.000000   \n",
       "\n",
       "          per_match  \n",
       "count  10000.000000  \n",
       "mean      60.131400  \n",
       "std       47.897753  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%      100.000000  \n",
       "75%      100.000000  \n",
       "max      100.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--Recall--\")# From the true positives - how many positives\n",
    "print(\"Mean average of entity match {} \".format(np.mean(result_proto1_df[\"per_match\"])))\n",
    "print(\"Median average of entity match {} \".format(np.median(result_proto1_df[\"per_match\"])))\n",
    "result_proto1_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save matches\n",
    "matched_df.to_csv(os.path.join(get_output_path(), \"results_proto_1.csv\"), sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
